# ğŸ¤– Configuration AI pour Gortex CLI

Gortex CLI peut utiliser l'intelligence artificielle pour gÃ©nÃ©rer automatiquement des messages de commit conventionnels basÃ©s sur vos changements.

## ğŸ“‹ Providers supportÃ©s

| Provider | Type | Avantages | PrÃ©requis |
|----------|------|-----------|-----------|
| **Ollama** | Local | Gratuit, privÃ©, aucune API key | Ollama installÃ© localement |
| **Mistral AI** | Cloud | Rapide, performant | API key Mistral |
| **OpenAI** | Cloud | TrÃ¨s performant | API key OpenAI |

---

## ğŸš€ Configuration rapide

### Option 1: Ollama (RecommandÃ© - Local & Gratuit)

**Ã‰tape 1**: Installer Ollama
```bash
# macOS/Linux
curl -fsSL https://ollama.com/install.sh | sh

# Windows
# TÃ©lÃ©chargez depuis https://ollama.com/download
```

**Ã‰tape 2**: TÃ©lÃ©charger le modÃ¨le
```bash
ollama pull mistral:7b
```

**Ã‰tape 3**: Configurer Gortex
CrÃ©ez un fichier `.gortexrc` Ã  la racine de votre projet :

```json
{
  "ai": {
    "enabled": true,
    "provider": "ollama",
    "ollama": {
      "model": "mistral:7b"
    }
  }
}
```

**Ã‰tape 4**: Tester
```bash
# Stagez des fichiers
git add .

# GÃ©nÃ©rez un commit avec l'AI
gortex ai-suggest
```

---

### Option 2: Mistral AI (API Cloud)

**Ã‰tape 1**: Obtenir une API key
1. Allez sur https://console.mistral.ai/
2. CrÃ©ez un compte
3. GÃ©nÃ©rez une API key dans la section "API Keys"

**Ã‰tape 2**: Configurer Gortex

**MÃ©thode A**: Via variable d'environnement (recommandÃ©)
```bash
export MISTRAL_API_KEY="votre_cle_api"
```

**MÃ©thode B**: Via `.gortexrc`
```json
{
  "ai": {
    "enabled": true,
    "provider": "mistral",
    "mistral": {
      "apiKey": "votre_cle_api",
      "model": "mistral-small-latest"
    }
  }
}
```

**Ã‰tape 3**: Tester
```bash
git add .
gortex ai-suggest
```

---

### Option 3: OpenAI (API Cloud)

**Ã‰tape 1**: Obtenir une API key
1. Allez sur https://platform.openai.com/
2. CrÃ©ez un compte
3. GÃ©nÃ©rez une API key dans la section "API Keys"

**Ã‰tape 2**: Configurer Gortex

**MÃ©thode A**: Via variable d'environnement (recommandÃ©)
```bash
export OPENAI_API_KEY="votre_cle_api"
```

**MÃ©thode B**: Via `.gortexrc`
```json
{
  "ai": {
    "enabled": true,
    "provider": "openai",
    "openai": {
      "apiKey": "votre_cle_api",
      "model": "gpt-4o-mini"
    }
  }
}
```

**Ã‰tape 3**: Tester
```bash
git add .
gortex ai-suggest
```

---

## âš™ï¸ Configuration avancÃ©e

### ModÃ¨les Ollama recommandÃ©s

| ModÃ¨le | Taille | RAM requise | Performance | Usage recommandÃ© |
|--------|--------|-------------|-------------|------------------|
| `mistral:7b` | 4.1 GB | 8 GB | â­â­â­â­ | **RecommandÃ©** - Ã‰quilibre qualitÃ©/vitesse |
| `phi:2.7b` | 1.6 GB | 4 GB | â­â­â­ | Machines limitÃ©es (laptops) |
| `mistral-nemo:12b` | 7 GB | 16 GB | â­â­â­â­â­ | Machines puissantes |
| `codestral:22b` | 13 GB | 24 GB | â­â­â­â­â­ | Workstations (focus code) |

### ModÃ¨les Mistral AI

| ModÃ¨le | Prix | Performance | Usage recommandÃ© |
|--------|------|-------------|------------------|
| `mistral-small-latest` | $ | â­â­â­â­ | **RecommandÃ©** - Bon rapport qualitÃ©/prix |
| `mistral-large-latest` | $$$ | â­â­â­â­â­ | Projets critiques |
| `codestral-latest` | $$ | â­â­â­â­â­ | SpÃ©cialisÃ© pour le code |

### ModÃ¨les OpenAI

| ModÃ¨le | Prix | Performance | Usage recommandÃ© |
|--------|------|-------------|------------------|
| `gpt-4o-mini` | $ | â­â­â­â­ | **RecommandÃ©** - Ã‰conomique et performant |
| `gpt-4o` | $$$ | â­â­â­â­â­ | Maximum de qualitÃ© |
| `gpt-4-turbo` | $$ | â­â­â­â­â­ | Bon compromis |

---

## ğŸ›ï¸ Options de configuration

### Configuration complÃ¨te `.gortexrc`

```json
{
  "ai": {
    "enabled": true,
    "provider": "ollama",

    "ollama": {
      "model": "mistral:7b",
      "baseUrl": "http://localhost:11434",
      "timeout": 30000
    },

    "mistral": {
      "apiKey": "${MISTRAL_API_KEY}",
      "model": "mistral-small-latest",
      "baseUrl": "https://api.mistral.ai"
    },

    "openai": {
      "apiKey": "${OPENAI_API_KEY}",
      "model": "gpt-4o-mini",
      "baseUrl": "https://api.openai.com"
    },

    "temperature": 0.3,
    "maxTokens": 500,
    "autoSuggest": false,
    "requireConfirmation": true
  }
}
```

### ParamÃ¨tres expliquÃ©s

| ParamÃ¨tre | Type | DÃ©faut | Description |
|-----------|------|--------|-------------|
| `enabled` | boolean | `false` | Active/dÃ©sactive l'AI |
| `provider` | string | `"ollama"` | Provider Ã  utiliser: `ollama`, `mistral`, `openai` |
| `temperature` | number | `0.3` | CrÃ©ativitÃ© (0.0-1.0). Plus bas = plus dÃ©terministe |
| `maxTokens` | number | `500` | Longueur max de la rÃ©ponse |
| `autoSuggest` | boolean | `false` | SuggÃ¨re automatiquement dans le workflow |
| `requireConfirmation` | boolean | `true` | Demande confirmation avant commit |

---

## ğŸ’¡ Utilisation

### Commande standalone
```bash
# Stagez des fichiers
git add src/api/auth.ts src/utils/jwt.ts

# GÃ©nÃ©rez une suggestion
gortex ai-suggest
```

### Output exemple
```
âœ¨ Suggestion gÃ©nÃ©rÃ©e par Ollama

Message de commit proposÃ©:
  feat(api): add JWT authentication middleware

  Implement JWT-based authentication middleware to secure
  API endpoints. Adds token validation and user context
  extraction for protected routes.

Raisonnement:
  The changes introduce new authentication functionality (feat),
  focused on the API layer (api scope). The middleware pattern
  and JWT utilities indicate a security feature addition.

Confiance: 87% ğŸ¯

â¯ Utiliser cette suggestion pour crÃ©er le commit ? (Y/n)
```

---

## ğŸ”§ Troubleshooting

### Ollama: "Provider non disponible"

**ProblÃ¨me**: Ollama n'est pas accessible

**Solutions**:
```bash
# VÃ©rifiez qu'Ollama tourne
ollama list

# DÃ©marrez le service
ollama serve

# VÃ©rifiez que le modÃ¨le est installÃ©
ollama pull mistral:7b

# Testez manuellement
ollama run mistral:7b "hello"
```

### Mistral/OpenAI: "API key manquante"

**ProblÃ¨me**: API key non configurÃ©e

**Solutions**:
```bash
# MÃ©thode 1: Variable d'environnement (recommandÃ©)
export MISTRAL_API_KEY="votre_cle"
export OPENAI_API_KEY="votre_cle"

# MÃ©thode 2: .env dans votre projet
echo "MISTRAL_API_KEY=votre_cle" >> .env

# MÃ©thode 3: .gortexrc (moins sÃ©curisÃ©)
# Ajoutez la clÃ© directement dans la config
```

### "Diff trop long"

**ProblÃ¨me**: Trop de changements stagÃ©s

**Solutions**:
```bash
# Committez par petits morceaux
git reset
git add src/specific-file.ts
gortex ai-suggest

# Ou augmentez la limite (dans le code analyzer.ts)
```

---

## ğŸ¯ Bonnes pratiques

### 1. Stagez intelligemment
```bash
# âŒ Ã‰vitez de tout stager d'un coup
git add .

# âœ… Stagez par fonctionnalitÃ© logique
git add src/api/auth.ts src/middleware/jwt.ts
gortex ai-suggest
```

### 2. VÃ©rifiez toujours la suggestion
L'AI est un **assistant**, pas un remplaÃ§ant. Toujours relire et ajuster si nÃ©cessaire.

### 3. Contexte clair
Plus vos changements sont cohÃ©rents et ciblÃ©s, meilleure sera la suggestion.

### 4. Scopes configurÃ©s
DÃ©finissez des scopes dans `.gortexrc` pour guider l'AI :
```json
{
  "scopes": ["api", "ui", "auth", "database", "config"]
}
```

---

## ğŸ”’ SÃ©curitÃ© & Vie privÃ©e

### Ollama (Local)
- âœ… **100% privÃ©** - Aucune donnÃ©e n'est envoyÃ©e en ligne
- âœ… Code source reste sur votre machine
- âœ… Aucun tracking

### Mistral AI / OpenAI (Cloud)
- âš ï¸ Votre **diff est envoyÃ©** au provider
- âš ï¸ Ne commitez **jamais** de secrets, tokens, ou donnÃ©es sensibles
- âœ… Utilisez `.gitignore` pour exclure les fichiers sensibles
- âœ… Les providers ne stockent pas vos donnÃ©es (selon leurs politiques)

---

## ğŸ“Š Comparaison des providers

| CritÃ¨re | Ollama | Mistral AI | OpenAI |
|---------|--------|------------|--------|
| **Prix** | Gratuit | ~0.001$/req | ~0.0001$/req |
| **Vitesse** | Moyenne (CPU-dependent) | Rapide | Rapide |
| **QualitÃ©** | Bonne | Excellente | Excellente |
| **Vie privÃ©e** | â­â­â­â­â­ | â­â­â­ | â­â­â­ |
| **Setup** | Complexe | Simple | Simple |
| **Offline** | âœ… Oui | âŒ Non | âŒ Non |

---

## ğŸš€ Prochaines Ã©tapes

1. **Configurez votre provider prÃ©fÃ©rÃ©**
2. **Testez sur de vrais commits**
3. **Ajustez `temperature` et `maxTokens` selon vos prÃ©fÃ©rences**
4. **Partagez votre config `.gortexrc` avec votre Ã©quipe**

---

## ğŸ“š Ressources

- [Ollama Documentation](https://ollama.com/docs)
- [Mistral AI API Docs](https://docs.mistral.ai/)
- [OpenAI API Docs](https://platform.openai.com/docs)
- [Conventional Commits](https://www.conventionalcommits.org/)

---

**Besoin d'aide ?** Ouvrez une issue sur [GitHub](https://github.com/ArthurDEV44/gortex-cli/issues)
